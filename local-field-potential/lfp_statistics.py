# -*- coding: utf-8 -*-
"""
Created on Mon Feb 10 17:07:26 2025

@author: ssenapat
"""

# read one channel at a time and separate it into indvidual clusters

def load_trigger():
    '''
    Returns
    -------
    sorted_trigger_loc : TYPE
        Generates trigger information for music pieces

    '''
    # read the saved trigger channel info
    # file = '/home/ssenapat/groups/PrimNeu/Final_exps_spikes/LFP/Elfie/p1/p1_15/trigger_onset_for_py.npy'
    file = Path('G:/Final_exps_spikes/LFP/Elfie/p1/p1_15/trigger_onset_for_py.npy')
    triggers = pd.DataFrame(np.load(file))
    
    return triggers



def load_onset_response(file):
    '''
    Returns
    -------
    sorted_trigger_loc : TYPE
        Generates trigger information for music pieces

    '''
    
    # read all saved onset response per channel info - generated by lfp_onset_response.py
    onsets = pd.read_csv(file, header=None)
    
    return onsets


def identify_channel(filepath):
    
    folder = str(filepath)     

    folder_name_loc = re.search(r"channel[0-9]+", folder)
    ind = folder_name_loc.span()
    channelID = folder[ind[0]+7:ind[1]]        # get rid of the 'LFP' at the start of the channel ID name
    
    return int(channelID)



def tones_per_channel(chan_matrix, channel_num, trigger, savehere):
    
    ### 
    save_loc = str(savehere) + '/data_for_statistics'
    if not os.path.exists(save_loc):     # if the required folder does not exist, create one
        os.mkdir(save_loc)
     
    chan_matrix_selected = chan_matrix.iloc[:,500:2000]
    chan_matrix_selected.columns = range(chan_matrix_selected.columns.size)     # don't forget to handle the column names of this subset
    
    
    # downsampling to get one datapoint for every 50 ms, i.e. 1 datapoint for every 125 datapoints
    downsampled_chan_matrix = np.zeros(12) 
    
    for condition in range(len(chan_matrix_selected)):
        # for each row at a time
        rowval = chan_matrix_selected.iloc[condition,:]
        mean_values_for_condition = []
        w = 0
        while w < chan_matrix_selected.columns.size:
            mean_per_window = np.mean(rowval[w:w+125])
            mean_values_for_condition = np.append(mean_values_for_condition, mean_per_window)
            w = w + 125
            
        downsampled_chan_matrix = np.vstack([downsampled_chan_matrix, mean_values_for_condition])
        
    downsampled_chan_matrix = np.delete(downsampled_chan_matrix, [0], axis=0) # remove 1st row, which is not crucial
        
    downsampled_chan_matrix_df = pd.DataFrame(downsampled_chan_matrix)
    downsampled_chan_matrix_df.to_csv(str(save_loc) + '/channel' + str(channel_num) + '_downsampled.csv', header=False, index=False)

    return downsampled_chan_matrix


def two_way_anova(window_matrix):
    
    # based on behavioral experiement paradigm
    condition_order = ['original', 'global_reversed','original','original','global_reversed','local_reversed','local_reversed','global_reversed','local_reversed']
    condition_speed = [66,75,85,75,85,75,66,66,85]
    
    # combine all information in a dataframe
    data_df = pd.DataFrame(window_matrix)
    data_df.rename(columns={0 : 'evoked_response'}, inplace=True)
    
    # add two factors
    data_df['order'] = np.repeat(condition_order, 10)
    data_df['speed'] = np.repeat(condition_speed, 10)
    
    model = ols('evoked_response ~ C(order) + C(speed) + C(order):C(speed)', data=data_df).fit() 
    result = sm.stats.anova_lm(model, type=2)
    
    print(result)


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
from pathlib import Path
import re

import statsmodels.api as sm 
from statsmodels.formula.api import ols 
    

#trigger = load_trigger()
   
directory = Path('G:/Final_exps_spikes/LFP/Elfie/p1/p1_15/onset_responses/')

channel_order = []
for chan in os.listdir(directory):
    filepath = str(directory) + '/' + chan
    onset_mat = load_onset_response(filepath)
    channel_num = identify_channel(filepath)       # identify current channel based on filepath
    
    channel_order.append(channel_num)
    
    # for each channel
    savehere = Path('G:/Final_exps_spikes/LFP/Elfie/p1/p1_15/')
    if not os.path.exists(savehere):     # if the required folder does not exist, create one
        os.mkdir(savehere)
    
    # every tone per channel
    modified_data = downsample_channel(onset_mat, channel_num, savehere)
    
    # add function to perform 2-way ANOVA
    for window in range(len(modified_matrix.T)):      # this should be 12
        two_way_anova(modified_matrix[:,window])
